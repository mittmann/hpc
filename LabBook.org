# -*- org-export-babel-evaluate: nil -*-
#+TITLE: Arthur Krause's LabBook
#+AUTHOR: Arthur Krause
#+LATEX_HEADER: \usepackage[margin=2cm,a4paper]{geometry}
#+STARTUP: overview indent
#+TAGS: Arthur(A) Lucas(L) noexport(n) deprecated(d)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

This document is in English.

* 2016-01-25 First entry (proper emacs configuration file)            :Lucas:

I recommend you use Arnaud's emacs configuration file, available here:
+ http://mescal.imag.fr/membres/arnaud.legrand/misc/init.php

* 2016-07-06 Kickoff meeting (discussion some ideas)           :Arthur:Lucas:

We talk about lots of things with the objective to define the IC topic
in the context of the HPC4E project. Arthur will write a paragraph
about the following topics:
- PAPI (hardware counters in general, tools to trace them)
- OpenMP specification (for shared memory parallel programming)
- MPI (for distributed/shared memory - message passing)
- StarPU (applications are written as a graph of tasks with
  dependencies)

Deadline: 08/07, meeting will take place at 3PM

* 2016-07-11 Text as requested by Lucas                              :Arthur:
Note: You can use M-q to limit yourself to 80-columns.

Hardware counters are special registers that track events in the
processor such as cache misses, branch prediction success rate,
instruction count and memory bandwidth. With this data, it's possible
to establish a relation between the performance of a program and the
architecture it is running on. There are various ways to extract their
data, the most common is through the perf command, but there are
others. PAPI provides an interface that groups the events in called
EventSets. With this it's possible to correlate performance drops with
cache misses or memory bandwith, for example, indicating a
bottleneck. Intel provides a C++ API called Performance Counter
Monitor (PCM). With PCM, the programmer is able to access hardware
counter values directly in the code. There are studies that show the
possibility to estimate the power used by the processor analyzing a
small subset of these hardware counters.

OpenMP is an API for multithreading. It allows the programmer to put
compiler directives inside the code signaling a section that should be
parallelized, with the advantages of being multiplataform and usable
on GPGPU. The Message Passing Interface (MPI) is a specification of
what a message passing interface should do and how it should be
implemented. There are implementations for nearly all HPC platforms
and the code is easily portable to any platform that supports
MPI. StarPU works like a scheduler that assigns tasks to the multiple
processing units available for the user (e.g. GPU and CPU) given that
the programmer has written code for that architecture. StarPU can use
different scheduling policies that takes into account different
metrics to make its decisions, such as performance or power.
* 2016-07-13 Suggestion of initial concepts exploration               :Lucas:
Techniques/Concepts to explore (suggestion):

- How to measure _hardware counters_ (in an Intel arch.)
- OpenMP: parallel for and task parallelism
- Write programs using OpenMP
  - Matrix multiplication (regular load)
  - Mandelbrot set (irregular load)
  - Heat transfer
- Learning about OpenMP (hands-on)
  - http://openmp.org/mp-documents/omp-hands-on-SC08.pdf

Other topics
- NUMA (a fat node)
- Consider learning about StarPU
  - http://starpu.gforge.inria.fr/
  - Task parallelism
- Literate programming
  - https://en.wikipedia.org/wiki/Literate_programming
  - Donald E. Knuth
* 2016-07-18 Implementing MM (Example of use of Org Mode for coding) :Arthur:

Here's the code of my MM application:

#+begin_src C :results output :session :exports both :tangle no
#include <stdio.h>
int main() { 
printf("oe");
return 0; }
#+end_src

#+RESULTS:
: oe

Tangle this file and compile like this:

#+begin_src sh :results output :session :exports both
gcc -o mm  mm.c  
#+end_src

#+RESULTS:

Now, execute this on machine =orion3=.

#+begin_src sh :results output :session :exports both :dir /ssh:orion2:~/
ls
#+end_src

#+RESULTS:
: misc

* 2016-07-18 Meeting with Arthur/Lucas                         :Arthur:Lucas:

HPC4E (Brazil-Europa)
- http://hpc4e.eu/
- Collaboration project

CMP134 - Introdução ao Processamento Paralelo e Distribuído
- https://moodle.inf.ufrgs.br/course/view.php?id=722

CMP134 at Bitbucket
- https://bitbucket.org/schnorr/cmp134

* 2016-07-19 Suggested problems implementation using OpenMP          :Arthur:
** Matrix Multiplication

Here's the Matrix Multiplication code that I've implemented using
OpenMP. It multiplies two square dynamically generated matrices of
doubles.  It's size can be adjusted by modifying SIZE. Each column or
row has SIZE elements. To test it yourself, start by tangling the MM
code.
  
#+begin_src C :results output :session :exports both :tangle mm.c
#Include <stdio.h>
#include <stdlib.h>
#include <omp.h>
#include <time.h>

#define SIZE 800

double mat1[SIZE][SIZE], mat2[SIZE][SIZE], mat3[SIZE][SIZE];

int main(int argc, char** argv)
{
        int row, col;
        double start_t;
        if (argc == 1)    omp_set_num_threads(1);
        else if (argc == 2)    omp_set_num_threads(atoi(argv[1]));
        else
        {
                puts("invalid amount of parameters");
                return -1;
        
        }

        srand(time(NULL));      
        for (row=0; row<SIZE; row++)
        {
                for(col=0; col<SIZE; col++)
                {
                        mat1[row][col] = (double)rand() + (double)rand()/(double)RAND_MAX;
                        mat2[row][col] = (double)rand() + (double)rand()/(double)RAND_MAX;
                }
        }
        start_t = omp_get_wtime();

        #pragma omp parallel
        { 
                int i, _col;
                #pragma omp for
                for (row=0; row<SIZE; row++)
                {
                        for(_col=0; _col<SIZE; _col++)
                        {
                                for (i=0; i<SIZE; i++)
                                        mat3[row][_col] += mat1[row][i] * mat2[i][_col];
                        }
                }
        }

        printf("%f", omp_get_wtime() - start_t);
}
#+end_src

#+RESULTS:

Then, run the following script to compile and test it. It runs the
program 5 times for each number of threads, from 1 to 4 and stores the
results in a .csv file. Each line contains the results for each number
of threads.

#+begin_src sh :results output :session :exports both
gcc -fopenmp mm.c
mv a.out mm
rm mmlog mmlog.csv 
for j in 1 2 3 4
do
 for i in 1 2 3 4 5
 do
     ./mm $j >> mmlog
     echo "," >> mmlog
 done
 ./mm $j >> mmlog
 cat mmlog | tr -d '\n' >> mmlog.csv
 rm mmlog
echo "" >> mmlog.csv
done
cat mmlog.csv
#+end_src

#+RESULTS:

Here are my results running in a Intel Core i5-4210U CPU

: 4.352094,4.362803,4.347984,4.288565,4.358691,4.308480
: 2.283323,2.296820,2.359130,2.300184,2.366097,2.302083
: 2.954205,2.466486,2.328566,2.723584,2.918361,2.289822
: 2.260569,2.251039,2.250062,2.240696,2.284846,2.280797
*** cpu specs
Arquitetura:           x86_64
CPU(s):                4
On-line CPU(s) list:   0-3
Thread(s) per núcleo  2
Núcleo(s) por soquete:2
Soquete(s):            1
Nó(s) de NUMA:        1
Model name:            Intel(R) Core(TM) i5-4210U CPU @ 1.70GHz
CPU max MHz:           2700,0000
CPU min MHz:           800,0000
cache de L1d:          32K
cache de L1i:          32K
cache de L2:           256K
cache de L3:           3072K
NUMA node0 CPU(s):     0-3
 
* 2016-07-20 Feedback on Krause's MM implementation                   :Lucas:

Arthur has presented his MM's parallel implementation here:
- [[*Matrix Multiplication][Matrix Multiplication]]

First, I give you some suggestions about the code:

1. Thinking about reproducibility, you should initialize your matrix
   always with the same values. So, instead of =srand(time(NULL));=, do
   something link =srand(0);=, using a constant value. Doing that, at
   every experimental replication you are sure you have the same
   scenario.
2. You probably noticed the long execution time to initialize your
   matrices. I suggest you to use the following function to generate
   "random" values:
   #+begin_src C :results output :session :exports both
   //next function has been found here:
   //http://stackoverflow.com/questions/26237419/faster-than-rand
   //all credits to the authors there
   static unsigned int g_seed = 0;
   static inline int fastrand()
   {
     g_seed = (214013*g_seed+2531011);
     return (g_seed>>16)&0x7FFF;
   }
   #+end_src
3. Your code should receive the matrix size as parameter. Keep
   allocating them in the data segment (as globals); use a upper bound
   size, make sure the argument is always smaller than that. Note that
   800 is considered to be small. The performance analysis of your
   program should contain size as factor.
4. Regarding the program compilation: use the =-O3= optimization flag to
   gcc; if you have time, use clang (another compiler) adopting the
   compiler as a factor for your performance analysis. Show how one
   compiler's code is faster than the other.

Then, I give some suggestions about the running script:

1. The output of your script should be a CSV in the following format:
   the first line is the header containing the name of the
   columns. The rest of the file has the measurements (one single
   measurement per line). Example of a file considering your scenario:
   #+BEGIN_EXAMPLE
   Time, Thread, Size, Compiler
   4.352094, 1, 800, gcc
   4.362803, 1, 800, gcc
   4.347984, 1, 800, gcc
   4.288565, 1, 800, gcc
   4.358691, 1, 800, gcc
   4.308480, 1, 800, gcc
   #+END_EXAMPLE
   It's okay to repeat the information.
2. You can write =for i in `seq 1 5`= instead of what you did.
3. Everything you echo within the for could be redirected to a file
   with a single command, like this:
   #+begin_src sh :results output :session :exports both
   for i in 1 2 3 4 5
   do
      ./mm $j
      echo ","
   done >> mmlog
   #+end_src
4. Your script should log the details of the experimental platform.
5. A problem with your script is that you do 5 replications in
   order. For instance with four threads: you do five replications in
   a row. You should randomize your experimental design. The best way
   to do so is not do by yourself, and use R instead (see below a
   suggestion of design for your case).

Recommendations regarding the experimental setup + other topics:

1. I strongly recommend you to start reading the book of Raj Jain 1991: 
   *The Art of Computer Systems Performance Analysis*.
   The INF/UFRGS library has some units. Or google it.
2. Please, learn about experimental design in this book (full
   factorial and fractional designs to start with). It is of major
   importance since you provides you sound experimental data if you
   correctly apply them.
3. Tangle the experimental script (but do not commit the tangled file).
4. Other random questions: there are three for loops: try to
   parallelize the others. Which for is the best to be parallelized?
   Try to use other OpenMP schedulers to see which one is best (you
   can use dynamic, static, guided). For the MM scenario, which one is
   best? Why?

_A Experimental Design for your MM Scenario_

This is very rough, post questions when in doubt.

In English:

- 10 replications
- 2 factors (matrix size and number of threads)
  - matrix size is 400, 800, 1600 (enrich if you want to)
  - number of threads is 1 (sequential), 2, 4, 8
    - Sequential should be the code compiled without =-fopenmp=
- outcomes are the execution time and name of the platform
- randomize experiments

So, in R:

#+begin_src R :results output :session *x*:exports both :tangle yes.r
  require(DoE.base);
  MM_Scenario <- fac.design (
           nfactors=2,
           replications=10,
           repeat.only=FALSE,
           blocks=1,
           randomize=TRUE,
           seed=10373,
           nlevels=c(3,4),
           factor.names=list(
                size=c(400, 800, 1600),
                threads=c(1, 2, 4, 8)));

  export.design(MM_Scenario,
                path=".",
                filename=NULL,
                type="csv",
                replace=TRUE,
                response.names=c("time","platform"));
#+end_src

#+RESULTS:
#+begin_example
Loading required package: DoE.base
Loading required package: grid
Loading required package: conf.design

Attaching package: ‘DoE.base’

The following objects are masked from ‘package:stats’:

    aov, lm

The following object is masked from ‘package:graphics’:

    plot.design

The following object is masked from ‘package:base’:

    lengths
 creating full factorial with 12 runs ...
#+end_example

You should have two files now:

#+begin_src sh :results output :session :exports both
ls MM_Scenario.*
#+end_src

#+RESULTS:
: MM_Scenario.csv
: MM_Scenario.rda

The first one has your experimental design, each line indicating an
experiment you should run with your MM implementation. Example:

#+begin_src sh :results output :session :exports both
head MM_Scenario.csv
#+end_src

#+RESULTS:
#+begin_example
"name","run.no.in.std.order","run.no","run.no.std.rp","size","threads","time","platform"
"1","5",1,"5.1","800","2","",""
"2","12",2,"12.1","1600","8","",""
"3","3",3,"3.1","1600","1","",""
"4","7",4,"7.1","400","4","",""
"5","10",5,"10.1","400","8","",""
"6","8",6,"8.1","800","4","",""
"7","6",7,"6.1","1600","2","",""
"8","1",8,"1.1","400","1","",""
"9","9",9,"9.1","1600","4","",""
#+end_example

You can see they are randomized and there is a bunch of columns.

What you should do:

- Create a bash script that takes the design CSV (=MM_Scenario.csv=) as
  input, and run your application with the correct factors'
  values. For the example above, the first execution should be with
  matrix size of 800, with 2 threads.
- The output of your script should be the exact values of the input
  CSV plus the execution time and the platform in the corresponding
  columns.

See this entry for an example of script:
- [[*2016-07-20 (Unrelated) Example of experimental bash script][2016-07-20 (Unrelated) Example of experimental bash script]]

* 2016-07-20 (Unrelated) Example of experimental bash script          :Lucas:
Below I show you another project we are playing with for another project:
- Post your questions when in doubt
#+begin_src sh :results output :session :exports both :tangle no
  #!/bin/bash

  # Screening_run.sh
  
  # For each line
  # get the name of the program (column 5)
  # get the input size (column 6)
  # Launch the experiment, get execution time
  # print the line, with the time.

  function usage()
  {
      echo "$0 <benchmark> <binary> <design> <unique> <low_freq> <high_freq> <cpus> <notdryrun>";
      echo "where <benchmark> is one of the supported benchmarks";
      echo "where <binary> is the string (the command) that will be executed";
      echo "where <unique> can be any unique identifier you might like";
  }

  # parameter handling
  # Check if the benchmark is supported
  BENCHMARK=$1
  if [ -n "$BENCHMARK" -a "$BENCHMARK" != "lulesh" -a "$BENCHMARK" != "graph500"  -a "$BENCHMARK" != "minife" ]; then
      usage;
      exit;
  fi

  BINARY=$2
  if [ -z "$BINARY" ]; then
      usage;
      echo "Common commands to be placed in binary:";
      echo "lulesh: \"./lulesh2.0 -i 1\"";
      echo "graph500: \"SKIP_VALIDATION=1 ./omp-csr -s 25\"";
      echo "minife: \"./miniFE.x nx=200\"";
      exit;
  fi

  DESIGN=$3
  if [ -z "$DESIGN" ]; then
      usage;
      exit;
  fi
  UNIQUE=$4
  if [ -z "$UNIQUE" ]; then
      usage;
      exit
  fi
  REDFST_LOW=$5
  if [ -z "$REDFST_LOW" ]; then
      usage;
      exit
  fi
  REDFST_HIGH=$6
  if [ -z "$REDFST_HIGH" ]; then
      usage;
      exit
  fi
  REDFST_CPUS=$7
  if [ -z "$REDFST_CPUS" ]; then
      usage;
      exit
  fi
  NOTDRYRUN=$8

  # Lulesh mapping
  declare -A regions
  if [ "$BENCHMARK" = "lulesh" ]; then
      regions[A]=1
      regions[B]=2
      regions[C]=3
      regions[D]=4
      regions[E]=5
      regions[F]=6
      regions[G]=7
      regions[H]=8
      regions[I]=9
      regions[J]=10
      regions[K]=11
      regions[L]=12
      regions[M]=13
      regions[N]=14
      regions[O]=15
      regions[P]=16
      regions[Q]=17
      regions[R]=18
      regions[S]=19
      regions[T]=20
      regions[U]=21
      regions[V]=22
      regions[X]=23
      regions[W]=24
      regions[Y]=25
      regions[Z]=26
      regions[AA]=27
      regions[BB]=28
      regions[CC]=29
      regions[DD]=30
  elif [ "$BENCHMARK" = "graph500" ]; then
      # Graph500 mapping
      regions[A]=0
      regions[B]=21
      regions[C]=22
      regions[D]=24
      regions[E]=25
      regions[F]=26
      regions[G]=27
      regions[H]=28
      regions[I]=29
      regions[J]=30
      regions[K]=32
      regions[L]=33
      regions[M]=34
      regions[N]=35
      regions[O]=37
      regions[P]=41
      regions[Q]=42
  elif [ "$BENCHMARK" = "minife" ]; then
      regions[A]=1
      regions[B]=2
      regions[C]=3
      regions[D]=4
      regions[E]=5
      regions[F]=6
      regions[G]=7
      regions[H]=8
      regions[I]=9
      regions[J]=10
      regions[K]=11
      regions[L]=12
      regions[M]=13
      regions[N]=14
      regions[O]=15
      regions[P]=16
      regions[Q]=17
      regions[R]=18
      regions[S]=19
      regions[T]=20
      regions[U]=21
      regions[V]=22
      regions[X]=23
      regions[Y]=24
      regions[W]=25
      regions[Z]=26
  fi

  HOSTNAME=`hostname`
  export OMP_PROC_BIND=TRUE

  #check if the MSR is loaded
  if [ `lsmod | grep msr | wc -l` -ne 1 ]; then
      echo "The =msr= module is not loaded. It should be."
      usage;
      exit;
  fi
  # disable turbo boost on all cpus
  # we'll do it for all cores because its easier, but
  # one core per cpu would make more sense
  for cpu in $(ls /sys/bus/cpu/devices|sed 's/.*cpu//'); do
    sudo wrmsr -p${cpu} 0x1a0 0x4000850089
    if [[ "0" = $(sudo rdmsr -p${cpu} 0x1a0 -f 38:38) ]]; then
      echo "Failed to disable turbo boost for cpu$cpu. Aborting."
      exit 1
    fi
  done

  #check if cpufreq-info is present
  if [ -z `which cpufreq-info` ]; then
      echo "The =cpufreq-info= tool should be available."
      usage;
      exit;
  fi

  #check if high/low limits are within bounds
  CPUFREQ_INFO=`cpufreq-info -p`
  echo "cpufreq-info -p informs \"$CPUFREQ_INFO\""
  CPUFREQ_LOW_LIMIT=`echo $CPUFREQ_INFO | cut -d" " -f1`
  CPUFREQ_HIGH_LIMIT=`echo $CPUFREQ_INFO | cut -d" " -f2`
  CPUFREQ_GOVERNOR=`echo $CPUFREQ_INFO | cut -d" " -f3`
  if [ $REDFST_LOW -gt $REDFST_HIGH ]; then
      echo "Low frequency $REDFST_LOW is higher than high frequency $REDFST_HIGH.";
      usage;
      exit;
  fi
  if [ $REDFST_LOW -lt $CPUFREQ_LOW_LIMIT ]; then
      echo "Low frequency $REDFST_LOW is lower than low limit ($CPUFREQ_LOW_LIMIT) informed by cpufreq-info.";
      usage;
      exit;
  fi
  if [ $REDFST_HIGH -gt $CPUFREQ_HIGH_LIMIT ]; then
      echo "High frequency $REDFST_HIGH is higher than high limit ($CPUFREQ_HIGH_LIMIT) informed by cpufreq-info.";
      usage;
      exit;
  fi
  if [ "$CPUFREQ_GOVERNOR" != "userspace" ]; then
      echo "The cpufreq governor should be defined as \"userspace\", but is $CPUFREQ_GOVERNOR."
      usage;
      exit;
  fi


  #which factors are present in this design (get from first line)
  FACTORS=`head -n1 $DESIGN | cut -d"," -f5-21 | sed -e "s/\"//g" -e "s/,/ /g"`

  while read -r line; do
      NAME=`echo $line | cut -d"," -f1 | sed -e "s/\"//g" -e "s/,/ /g"`


      LEVELS=`echo $line | cut -d"," -f5-21 | sed -e "s/\"//g" -e "s/,/ /g"`
      COUNT=`echo $LEVELS | wc -w`
      #ignore first line
      if [[ $LEVELS =~ .*[[:alpha:]].* ]]; then
          #save first line of the design for later
          FIRSTDESIGNLINE="#G5K_REDFST#$line,unique,low,high,cpus,lowlimit,highlimit,governor,hostname"
          continue;
      fi

      echo
      echo "Starting experiment $NAME"
      echo "Starting at `date` on $HOSTNAME"
      echo

      #built LOW and HIGH variables
      REDFST_FASTREGIONS=
      REDFST_SLOWREGIONS=
      for i in `seq 1 $COUNT`; do
          FACTOR=`echo $FACTORS | cut -d" " -f$i`
          LEVEL=`echo $LEVELS | cut -d" " -f$i`
          if [[ $LEVEL =~ -1 ]]; then
              REDFST_SLOWREGIONS="${regions[$FACTOR]},$REDFST_SLOWREGIONS"
          elif [[ $LEVEL =~ 1 ]]; then
              REDFST_FASTREGIONS="${regions[$FACTOR]},$REDFST_FASTREGIONS"
          fi
      done
      #clean-up
      export REDFST_SLOWREGIONS=`echo $REDFST_SLOWREGIONS | sed "s/,$//"`
      export REDFST_FASTREGIONS=`echo $REDFST_FASTREGIONS | sed "s/,$//"`

      STDOUT=`tempfile`
      STDERR=`tempfile`
      REDFST=`tempfile`
      REDTRA=`tempfile`

      COMMAND="REDFST_FASTREGIONS=$REDFST_FASTREGIONS REDFST_SLOWREGIONS=$REDFST_SLOWREGIONS REDFST_LOW=$REDFST_LOW REDFST_HIGH=$REDFST_HIGH REDFST_CPUS=$REDFST_CPUS OMP_PROC_BIND=TRUE REDFST_HEADER=1 ${BINARY} 1> $STDOUT 2> $STDERR 3> $REDFST 4> $REDTRA"
      echo "COMMAND=\"$COMMAND\""
      if [ "$NOTDRYRUN" ]; then
          eval $COMMAND
      fi

      cat $STDOUT | sed "s/^/#STDOUT#/"
      cat $STDERR | sed "s/^/#STDERR#/"

      #output header
      echo "$FIRSTDESIGNLINE,`head -n1 $REDFST`"
      #output measurements
      cat $REDFST | tail -n+2 | sed "s/^/#REDFST#$line,$UNIQUE,$REDFST_LOW,$REDFST_HIGH,`echo $REDFST_CPUS | sed "s/,/-/g"`,$CPUFREQ_LOW_LIMIT,$CPUFREQ_HIGH_LIMIT,$CPUFREQ_GOVERNOR,$HOSTNAME,/"
      #output trace
      cat $REDTRA | sed "s/^/#REDTRA#/"

      rm -f $STDOUT $STDERR $REDFST $REDTRA

      echo
      echo "Finishing at `date` on $HOSTNAME"
      echo "Finishing experiment $NAME"
      echo

  done < $DESIGN

#+end_src
* 2016-07-20 How to avoid =org-babel-load-file= every time Emacs starts :Lucas:

Check:
- http://mescal.imag.fr/membres/arnaud.legrand/misc/init.html

Note that in the =Installation= section, you have the following lines:

Copy the =init.org= file to here =~/.emacs.d/init.org=.
http://mescal.imag.fr/membres/arnaud.legrand/misc/init.org

Once you did that, do =org-babel-load-file=. Provide the init.org file
that is within the =~/.emacs.d/= directory. When you do so, the loading
of the file creates another file called =init.el=. That file (with all
the special configurations from Arnaud) should be loaded automatically
next time you run emacs.

Let me know if that doesn't work for you.

* 2016-08-01 MM implementation following Lucas' suggested modifications :Arthur: 

This is the code from 2016-07-19 with the following modifications:
    - rand() is now replaced by fastrand() as the professor requested.
    - the matrix size is now a parameter received from the command line

#+begin_src C :results output :session :exports both :tangle mmv1.c
    
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>
#include <time.h>

#define MAX_SIZE 1600


double mat1[MAX_SIZE][MAX_SIZE], mat2[MAX_SIZE][MAX_SIZE], mat3[MAX_SIZE][MAX_SIZE];
static unsigned int g_seed = 0;
static inline int fastrand()
{
     g_seed = (214013*g_seed+2531011);
     return (g_seed>>16)&0x7FFF;
}


int main(int argc, char** argv)
{
        int row, col, size;
        double start_t;
        if (argc == 3) 
	{
		omp_set_num_threads(atoi(argv[1]));
		size = atoi(argv[2]);
		if (size > MAX_SIZE)
			{
				printf("Maximum matrix size is %d!", MAX_SIZE);
				return -1;
			}
	}
        else
        {
                puts("invalid amount of parameters");
                return -1;
        }

        for (row=0; row<size; row++)
        {
                for(col=0; col<size; col++)
                {
                        mat1[row][col] = (double)fastrand() + (double)fastrand()/(double)RAND_MAX;
                        mat2[row][col] = (double)fastrand() + (double)fastrand()/(double)RAND_MAX;
                }
        }
        start_t = omp_get_wtime();

        #pragma omp parallel
        { 
                int i, _col;
                #pragma omp for
                for (row=0; row<size; row++)
                {
                        for(_col=0; _col<size; _col++)
                        {
                                for (i=0; i<size; i++)
                                        mat3[row][_col] += mat1[row][i] * mat2[i][_col];
                        }
                }
        }

        printf("%f", omp_get_wtime() - start_t);
}
    #+end_src
    
First, create a folder for the logs and test scripts if it doesn't
exist already

#+begin_src sh :results output :session :exports both 
#!/bin/sh
mkdir log
mkdir scripts
#+end_src

#+RESULTS:

Now, tangle the following script that will compile and run the program
with different thread amounts and matrix sizes and store the results

#+begin_src sh :results output :session :exports both :tangle no
#!/bin/sh
#!/bin/bash

gcc -fopenmp -O3 mmv1.c
mv a.out mmv1

echo "Time, Threads, Size, Compiler" > log/mmv1.csv

for i in seq `seq 1 150`
do

THREADS=$((RANDOM % 4))
SIZE=$((RANDOM % 3))

if [ "$THREADS" == "0" ]; then
        THREADS=1

elif [ "$THREADS" == "1" ]; then
        THREADS=2

elif [ "$THREADS" == "2" ]; then
        THREADS=4

elif [ "$THREADS" == "3" ]; then
        THREADS=8
fi


if [ "$SIZE" == "0" ]; then
        SIZE=400

elif [ "$SIZE" == "1" ]; then
        SIZE=800

elif [ "$SIZE" == "2" ]; then
        SIZE=1600
fi


        ./mmv1 $THREADS $SIZE
        echo ", $THREADS, $SIZE, gcc"
done >> log/mmv1.csv

lscpu > log/mmv1_platform.txt

#+end_src


And finally, let's run the script

#+BEGIN_SRC sh :results output :session :exports both
  chmod +x scripts/test_mmv1.sh
  cat scripts/test_mmv1.sh | bash
  cat log/mmv1.csv
#+END_SRC

#+RESULTS:

* 2016-08-09 Reading a bash file line by line, then splitting         :Lucas:

This can be used to read a CSV file (the one whose name is registered
in the environment variable =$DESIGN=) where lines are separated by
commas. You can adapt it to your own needs since this example is very
particular to one scenario.

#+begin_src sh :results output :session :exports both
 while read -r line; do
      LEVELS=`echo $line | cut -d"," -f5-21 | sed -e "s/\"//g" -e "s/,/ /g"`
      #ignore first line
      if [[ $LEVELS =~ .*[[:alpha:]].* ]]; then
          #save first line of the design for later
          FIRSTDESIGNLINE="#G5K_REDFST#$line,unique,low,high,cpus,lowlimit,highlimit,governor,hostname"
          continue;
      fi
  done < $DESIGN
#+end_src
* 2016-08-10 Note on how to install clang with openmp                :Arthur:

inside an empty directory:
$ git clone https://github.com/clang-omp/llvm
$ git clone https://github.com/clang-omp/compiler-rt llvm/projects/compiler-rt
$ git clone -b clang-omp https://github.com/clang-omp/clangllvm/tools/clang

go to the llvm/projects folder:
$ svn co http://llvm.org/svn/llvm-project/openmp/trunk openmp
$ cd ..
$ mkdir build && cd build
$ cmake ../llvm -DCMAKE_COMPILER=gcc> -DCMAKE_CXX_COMPILER=g++
$ make omp


add this to /etc/environment 
C_INCLUDE_PATH="/home/arthur/openmpclang/llvm/projects/openmp/runtime/exports/common/include"
CPLUS_INCLUDE_PATH="/home/arthur/openmpclang/llvm/projects/openmp/runtime/exports/common/include"
LIBRARY_PATH="/home/arthur/openmpclang/llvm/projects/openmp/runtime/exports/lin_32e/lib"

create a random .conf file inside //etc/ld.so.conf.d/ and paste this inside
<PATH TO THE LLVM DIRECTORY>/llvm/projects/openmp/runtime/exports/lin_32e/lib

$ sudo ldconfig

* 2016-08-10 MM implementation using R and a better bash script      :Arthur:
Use R to create a test scenario with 512, 724, 1024 and 1448 (each one
has double the number of elements) with 1, 2, 3, 4 and 8 threads (1
still compiles as a parallel program but with only one thread) and
running the version compiled with gcc or clang.

#+begin_src R :results output :session :exports both :tangle MM_Scenario.r
  require(DoE.base);
  MM_Scenario <- fac.design (
           nfactors=3,
           replications=10,
           repeat.only=FALSE,
           blocks=1,
           randomize=TRUE,
           seed=10373,
           nlevels=c(4,4,2),
           factor.names=list(
                size=c(512, 724, 1024, 1448),
                threads=c(1, 2, 4, 8),
                compiler=c("gcc","clang")
           ));

  export.design(MM_Scenario,
                path=".",
                filename=NULL,
                type="csv",
                replace=TRUE,
                response.names=c("time"));
#+end_src

#+RESULTS:
#+begin_example
Loading required package: DoE.base
Loading required package: grid
Loading required package: conf.design

Attaching package: ‘DoE.base’

The following objects are masked from ‘package:stats’:

    aov, lm

The following object is masked from ‘package:graphics’:

    plot.design

The following object is masked from ‘package:base’:

    lengths
 creating full factorial with 32 runs ...
#+end_example

The following script runs the test scenario that R created:

#+begin_src bash :results output :session :exports both :tangle scripts/test_mmv1_2.sh
#!/bin/bash
gcc -fopenmp -O3 mmv1.c
mv a.out mmv1_gcc
clang -fopenmp -O3 mmv1.c
mv a.out mmv1_clang
while IFS="," read f1 f2 f3 f4 f5 f6 f7 f8 
do
        if [ "$f1" != "\"name\"" ]; then
                THREADS=${f6//\"/}
                SIZE=${f5//\"/}
                if [ "$f7" == "\"gcc\"" ]; then
                       TIME=$(./mmv1_gcc $THREADS $SIZE)
                else
                       TIME=$(./mmv1_clang $THREADS $SIZE)
                fi
                echo "$f1,$f2,$f3,$f4,$f5,$f6,$f7,$TIME"
	  else 
	      echo "$f1,$f2,$f3,$f4,$f5,$f6,$f7,$f8"
        fi
done < MM_Scenario.csv > data/MM_output.csv

#+end_src

#+RESULTS:

* 2016-08-17 Plotting the results                                    :Arthur:
The following script will parse the test output for 32 different
combinations of tests and calculate the mean between the results

#+begin_src bash :results output :session :exports both :tangle no
#!/bin/bash
while IFS="," read f1 f2 f3 f4 f5 f6 f7 f8 
do
        if [ "$f1" != "\"name\"" ]; then
                THREADS=${f6//\"/}
                SIZE=${f5//\"/}
		  COMPILER=${f7//\"/}
		  SET=${f2//\"/}
		  TIME=${f8//\"/}
		  TEST=${f4//\"/}

		  
		  if [[ $TEST =~ $SET.1$ ]]; then
		    TIMES[$SET]=$TIME
		  else
		      TEMP=${TIMES[$SET]}
		  
		      TIMES[$SET]=`echo $TEMP + $TIME | bc`
		   
                fi
               
	  else 
	      
        fi
done < MM_output.csv
for SET in `seq 1 32`
do
    TIMES[$SET]=`echo "scale=6; ${TIMES[$SET]}/10" | bc`
    echo ${TIMES[$SET]}
done
#+end_src

#+RESULTS:
#+begin_example
"name","run.no.in.std.order","run.no","run.no.std.rp","size","threads","compiler"
.334225
1.058921
4.160997
12.481441
.186360
.617012
2.421287
6.919256
.136020
.415052
1.464716
4.735039
.131582
.373843
1.533235
4.993605
.288431
.957739
3.984647
11.973237
.156525
.560240
2.290977
6.796627
.151007
.430680
1.607344
4.798753
.118542
.391772
1.657193
4.934918
#+end_example
* 2016-08-18 Feedback                                                 :Lucas:

- you should commit the file =MM_output.csv= to the repository
  - you may create a =data= directory for that
- you should not calculate the average by yourself using bash
  - use R and the =dplyr= package instead
  - it can be as easy as:
    #+begin_src R :results output :session :exports both
    df <- read.csv("measures.csv");
    #suppose first column has the timings
    m <- mean(df$8);
    m
    #+end_src

    #+RESULTS:
    : Error in file(file, "rt") : não é possível abrir a conexão
    : Além disso: Warning message:
    : In file(file, "rt") :
    :   não foi possível abrir o arquivo 'measures.csv': Arquivo ou diretório não encontrado
    : Erro: unexpected numeric constant in "    m <- mean(df$8"
    : [1] NA

- your =mm.c= is empty:
  #+begin_src sh :results output
  cat mm.c
  #+end_src

  #+RESULTS:
  : #include <stdio.h>
  : int main() { return 0; }

  - where is it?
- Where is the comparison of your =mm.c= compilation using gcc and clang?
- Get in touch with me more frequently (daily if necessary) to advance faster

* 2016-08-22 MM Perf. Analysis with different compilers        :Arthur:Lucas:
** Results with O3 optimization level
*** Understand the data
#+begin_src R :results output :session :exports both
df <- read.csv("data/MM_output.csv");
head(df);
#+end_src

#+RESULTS:
:   name run.no.in.std.order run.no run.no.std.rp size threads compiler     time
: 1    1                  14      1          14.1  724       8      gcc 0.331328
: 2    2                  32      2          32.1 1448       8    clang 3.861296
: 3    3                   8      3           8.1 1448       2      gcc 6.376965
: 4    4                  23      4          23.1 1024       2    clang 2.077688
: 5    5                  10      5          10.1  724       4      gcc 0.338524
: 6    6                  11      6          11.1 1024       4      gcc 1.215392

You also have played with the size.

*** Analysis of the results
#+begin_src R :results output graphics :file img/MM_output_O3.png :exports both :width 400 :height 400 :session
df <- read.csv("data/MM_output.csv");
library(dplyr);
k <- df %>% select(size, threads, compiler, time) %>% group_by(size, threads, compiler) %>%
                      summarize(N=n(), mean=mean(time), se=3*sd(time)/sqrt(n())) %>% as.data.frame();
library(ggplot2);
ggplot(k, aes(x=as.factor(threads), y=mean, color=compiler)) +
    geom_point() +
    geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.2) +
    theme_bw(base_size = 22) +
    ylim(0,NA) +
    ylab ("Runtime (seconds)") +
    xlab ("Number of threads") +
    scale_color_discrete (name="Compiler") +
    theme(legend.position="top") + 
    facet_wrap(~size, scales="free_y");
#+end_src

#+RESULTS:
[[file:img/MM_output_O3.png]]


**** Your interpretation

 The time for execution reduces almost by half doubling the amount of
 threads until 4, wich is the numer of cores on the machine used for
 testing. With 8 threads, the time is greater than with 4 because
 there is no parallelism gained since there is only 4 cores, and there
 is more scheduler overhead with 8 than with 4 threads. The scheduler
 overhead is also the reason for why the time for 2 is a bit greater
 than half the time for 1 thread. The same thing happens for 4 and 2
 threads.
 
 The test also reveals a better performance on the program compiled
 with llvm rather than gcc with -O3 optimization flag set. The llvm
 compiled program also showed a smaller standar error in the execution
 time than its counterpart compiled with gcc.
**** TODO Reinterpret considering the different matrix sizes
- State "TODO"       from              [2016-09-14 Wed 07:00]
** Results with O0 (no optimization)
*** Preparation for the next experiments _with no optimizations_
 To check if llvm gained performance with a better optimization we can
 compile with no compiler optimization at all and check the results.
 
 For this:
#+begin_src R :results output :session :exports both :tangle no
  require(DoE.base);
  MM_Scenario_O0 <- fac.design (
           nfactors=2,
           replications=10,
           repeat.only=FALSE,
           blocks=1,
           randomize=TRUE,
           seed=10373,
           nlevels=c(4,2),
           factor.names=list(
                threads=c(1, 2, 4, 8),
                compiler=c("gcc","clang")
           ));

  export.design(MM_Scenario_O0,
                path=".",
                filename=NULL,
                type="csv",
                replace=TRUE,
                response.names=c("time"));
#+end_src

#+RESULTS:
#+begin_example
Loading required package: DoE.base
Loading required package: grid
Loading required package: conf.design

Attaching package: ‘DoE.base’

The following objects are masked from ‘package:stats’:

    aov, lm

The following object is masked from ‘package:graphics’:

    plot.design

The following object is masked from ‘package:base’:

    lengths
 creating full factorial with 8 runs ...
#+end_example


#+begin_src bash :results output :session :exports both :tangle no
#!/bin/bash
gcc -fopenmp -O0 mmv1.c
mv a.out mmv1_O0_gcc
clang -fopenmp -O0 mmv1.c
mv a.out mmv1_O0_clang
while IFS="," read f1 f2 f3 f4 f5 f6 f7 
do
        if [ "$f1" != "\"name\"" ]; then
                COMPILER=${f6//\"/}
                THREADS=${f5//\"/}
                TIME=$(./mmv1_O0_$COMPILER $THREADS 1024)

                echo "$f1,$f2,$f3,$f4,$f5,$f6,$TIME"
	  else 
	      echo "$f1,$f2,$f3,$f4,$f5,$f6,$f7"
        fi
done < MM_Scenario_O0.csv > data/MM_output_O0.csv

rm mmv1_O0_gcc mmv1_O0_clang
#+end_src

#+RESULTS:
*** TODO Understand the measure data
- State "TODO"       from              [2016-09-14 Wed 07:03]
#+begin_src R :results output :session :exports both
df <- read.csv("data/MM_output_O0.csv");
head(df);
#+end_src

I don't understand why you have supressed the *size* parameters of your
DoE described here:
- [[*Preparation for the next experiments _with no optimizations_][Preparation for the next experiments _with no optimizations_]]

Please, create a new entry at the end of the LabBook with a DoE with
the size parameter (same sizes you have previously used for O3). Rerun
the experiments so we can not only compare within O0, but against O3
as well. It would be much better if your DoE had the optimization
level as a factor (you could have all the four levels: 0, 1, 2 and 3).


*** Analysis of the results
Since there is no size factor, I take it out. What was the size used
here?
#+begin_src R :results output :session :exports both
df <- read.csv("data/MM_output_O0.csv");
head(df);
library(dplyr);
k <- df %>% select(threads, compiler, time) %>% group_by(threads, compiler) %>%
                      summarize(N=n(), mean=mean(time), se=3*sd(time)/sqrt(n())) %>% as.data.frame();
k
#+end_src

#+RESULTS:
#+begin_example
  name run.no.in.std.order run.no run.no.std.rp threads compiler      time
1    1                   4      1           4.1       8      gcc  3.848389
2    2                   8      2           8.1       8    clang  3.056484
3    3                   2      3           2.1       2      gcc  7.556800
4    4                   7      4           7.1       4    clang  3.020419
5    5                   6      5           6.1       2    clang  6.105754
6    6                   5      6           5.1       1    clang 11.903840
  threads compiler  N      mean          se
1       1    clang 10 11.909524 0.003175097
2       1      gcc 10 14.856414 0.003287345
3       2    clang 10  6.104234 0.004152455
4       2      gcc 10  7.565980 0.016595808
5       4    clang 10  3.173850 0.130747388
6       4      gcc 10  4.069532 0.148892384
7       8    clang 10  3.164443 0.109269834
8       8      gcc 10  4.086618 0.175229557
#+end_example

#+begin_src R :results output graphics :file img/MM_output_O0.png :exports both :width 400 :height 400 :session
df <- read.csv("data/MM_output_O0.csv");
library(dplyr);
k <- df %>% select(threads, compiler, time) %>% group_by(threads, compiler) %>%
                      summarize(N=n(), mean=mean(time), se=3*sd(time)/sqrt(n())) %>% as.data.frame();
library(ggplot2);
ggplot(k, aes(x=as.factor(threads), y=mean, color=compiler)) +
    geom_point() +
    geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.2) +
    theme_bw(base_size = 22) +
    ylim(0,NA) +
    ylab ("Runtime (seconds)") +
    xlab ("Number of threads") +
    scale_color_discrete (name="Compiler") +
    theme(legend.position="top");
#+end_src

#+RESULTS:
[[file:img/MM_output_O0.png]]

 The program compilated with llvm is still better than the one
 compiled with gcc for this MM implementation
* 2016-09-14 Next steps towards *Performance Regression Test*          :Lucas:
** New DoE to test your matrix multiplication
Factors:
- optimization: 0, 1, 2 and 3
- compiler: clang, gcc
- matrix size: small, medium, big, huge
- threads: 1, 2, 4, 8, 16, 32
Outcomes:
- execution time
- total number of cache misses (L2, L3)

Please, ask Matthias Diener to have access to the *turing* machine.
** Learn about Spack to do Performance Regression Test
http://spack.readthedocs.io/en/latest/

How to install:
#+begin_src sh :results output
git clone https://github.com/llnl/spack.git
source spack/share/spack/setup-env.sh
#+end_src

My idea is that besides testing the optimization level and the
compiler, you would also use the *compiler version*. With spack, this
becomes very easy since you can have multiple compiler versions
installed in your HOME directory (each compiler version has a slightly
different OpenMP implementation, so one would expect different
parallel performance). The next step is to include all compiler
versions in your FF DoE.
** What is your application?
Several possibilities:
- Your matrix multiplication (you can use for your first tests)
- A very well optimization matrix multiplication: =dgemm=
- Cholesky factorization =dpotrf= (included in the chameleon spack's package)
- Irregular applications (such as those in my Reppar paper)
  https://github.com/lfgmillani/reppar2016
** Conduct a state of the art investigation
Search for "performance regression test" for the applications listed previously.
* 2016-09-21 Testing the MM with variable optimization levels        :Arthur:

I had removed the size factor in the previous test because the llvm
version had better performance with all sizes and, in order to reduce
the running time, I opted to test only for 1024x1024 matrices because
I tought that would be enough to find out if the different
optimization was the reason for the shorter execution time.

But anyways, here is the DoE with size and optimization levels as
factors:
** DoE
#+begin_src R :results output :session :exports both :tangle MM_Scenario.r
  require(DoE.base);
  MM_Scenario <- fac.design (
           nfactors=4,
           replications=20,
           repeat.only=FALSE,
           blocks=1,
           randomize=TRUE,
           seed=10373,
           nlevels=c(4,4,4,2),
           factor.names=list(
                size=c(512, 724, 1024, 1448),
                threads=c(1, 2, 4, 8),
                optimization=c("O0", "O1", "O2", "O3"),
                compiler=c("gcc","clang")
           ));

  export.design(MM_Scenario,
                path=".",
                filename=NULL,
                type="csv",
                replace=TRUE,
                response.names=c("time"));
#+end_src

#+RESULTS:
:  creating full factorial with 128 runs ...

** Script for testing
#+begin_src bash :results output :session :exports both :tangle scripts/test_mmv1.sh
#!/bin/bash
gcc -fopenmp -O0 mmv1.c
mv a.out mmv1_gcc_O0
gcc -fopenmp -O1 mmv1.c
mv a.out mmv1_gcc_O1
gcc -fopenmp -O2 mmv1.c
mv a.out mmv1_gcc_O2
gcc -fopenmp -O3 mmv1.c
mv a.out mmv1_gcc_O3
clang -fopenmp -O0 mmv1.c
mv a.out mmv1_clang_O0
clang -fopenmp -O1 mmv1.c
mv a.out mmv1_clang_O1
clang -fopenmp -O2 mmv1.c
mv a.out mmv1_clang_O2
clang -fopenmp -O3 mmv1.c
mv a.out mmv1_clang_O3
while IFS="," read f1 f2 f3 f4 f5 f6 f7 f8 f9
do
        if [ "$f1" != "\"name\"" ]; then
                THREADS=${f6//\"/}
                SIZE=${f5//\"/}
		  OPTIMIZATION=${f7//\"/}
                if [ "$f7" == "\"gcc\"" ]; then
                       TIME=$(./mmv1_gcc_$OPTIMIZATION $THREADS $SIZE)
                else
                       TIME=$(./mmv1_clang_$OPTIMIZATION $THREADS $SIZE)
                fi
                echo "$f1,$f2,$f3,$f4,$f5,$f6,$f7,$f8,$TIME"
	  else 
	      echo "$f1,$f2,$f3,$f4,$f5,$f6,$f7,$f8,$f9"
        fi
done < MM_Scenario.csv > data/MM_output.csv
rm -rf mmv1_gcc_*
rm -rf mmv1_clang_*

#+end_src

** Plotting the results

I'm not sure about how to plot these results. The more obvious for me are:

- y=time x=optimization, with fixed matrix size and thread amount,
  compare the execution time difference with compiling optimization
  for each compiler
- y=time x=threads, with fixed matrix size and one grahp for each
  optimization level, compare the performance gain with increased
  threads for each compiler with different optimization levels
 
Executing the second one:

#+begin_src R :results output :session :exports both
df <- read.csv("data/MM_output.csv");
head(df);
library(dplyr);
k <- df %>% select(threads, compiler,optimization, size, time) %>% group_by(threads, compiler, optimization, size) %>%
                      summarize(N=n(), mean=mean(time), se=3*sd(time)/sqrt(n())) %>% as.data.frame();
#+end_src

#+RESULTS:
#+begin_example
  name run.no.in.std.order run.no run.no.std.rp size threads optimization
1    1                  53      1          53.1  512       2           O3
2    2                  58      2          58.1  724       4           O3
3    3                  33      3          33.1  512       1           O2
4    4                  97      4          97.1  512       1           O2
5    5                  42      5          42.1  724       4           O2
6    6                  49      6          49.1  512       1           O3
  compiler     time
1      gcc 0.144429
2      gcc 0.314401
3      gcc 0.286600
4    clang 0.286353
5      gcc 0.345997
6      gcc 0.286512

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union
#+end_example

#+begin_src R :results output graphics :file img/MM_output.pdf :exports both :session
df <- read.csv("data/MM_output.csv");
library(dplyr);
k <- df %>% select(threads, compiler, optimization, size, time) %>% group_by(threads, compiler, optimization, size) %>%
                      summarize(N=n(), mean=mean(time), se=3*sd(time)/sqrt(n())) %>% as.data.frame();
library(ggplot2);
a <- k[k$size==1448,]
ggplot(a, aes(x=as.factor(threads), y=mean, color=compiler, group=optimization)) +
    geom_point() +
    geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.2) +
    theme_bw(base_size = 14) +
    ylim(0,NA) +
    ylab ("Runtime (seconds)") +
    xlab ("Number of threads") +
    scale_color_discrete (name="Compiler") +
    facet_wrap(~optimization) +
    theme(legend.position="top");
#+end_src

#+RESULTS:
[[file:img/MM_output.pdf]]

 This graph was not effective in showing differences between the
 compilers, so let's try to plot the percentual differences between
 the execution times.

 I couldn't do it. Could you help me, Lucas?


* 2016-09-23 New DoE considering cache misses                        :Arthur: 
#+begin_src R :results output :session :exports both :tangle MM_Scenario.r
  require(DoE.base);
  MM_Scenario_2 <- fac.design (
           nfactors=4,
           replications=15,
           repeat.only=FALSE,
           blocks=1,
           randomize=TRUE,
           seed=10373,
           nlevels=c(4,6,4,2),
           factor.names=list(
                size=c(512, 1024, 2048, 4096),
                threads=c(1, 2, 4, 8, 16, 32),
                optimization=c("O0", "O1", "O2", "O3"),
                compiler=c("gcc","clang")
           ));

  export.design(MM_Scenario_2,
                path=".",
                filename=NULL,
                type="csv",
                replace=TRUE,
                response.names=c("time", "L2.misses", "L3.misses"));
#+end_src

#+RESULTS:
:  creating full factorial with 192 runs ...


The initial idea to count cache misses is through the perf utility, as
the example below

The output here in the LabBook is not the same when run directly into
bash, though
#+begin_src bash :results output :session :exports both
perf stat -B -e cache-references,cache-misses,L1-dcache-load-misses,LLC-loads-misses,cycles,instructions,branches ./mmv1_gcc 1 1000
#+end_src

#+RESULTS:
: 13.837267

    


Performance counter stats for './mmv1_gcc 32 1600':

    63.107.326.309 L1-dcache-loads                                              [22,99%]
     8.406.134.775 L1-dcache-stores                                             [35,43%]
     4.117.398.031 L1-dcache-load-misses     #    6,52% of all L1-dcache hits   [47,87%]
         3.071.692 L1-dcache-store-misses                                       [49,87%]
     4.148.736.630 LLC-loads                                                    [45,90%]
         1.302.953 LLC-stores                                                   [10,11%]
        55.854.974 LLC-loads-misses          #    1,35% of all LL-cache hits    [10,27%]
           561.544 LLC-stores-misses                                            [10,53%]

       3,839903229 seconds time elapsed


The plan was to subtract the L1 misses from the LLC loads and stores
in order to get the number of L2 hits, the problem is that it yields a
negative number, so this data is obviously incorrect.

     
 
 Is this correct, Lucas? Could you point me to a better way of getting this data?
